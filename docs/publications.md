
## Monographs

* **Bengs, V.** (2018). *Confidence sets for change-point problems in nonparametric regression*. Ph.D. thesis, Philipps-Universität Marburg.

## Journal Publications

* **Bengs, V., Eulert, M.**, and **Holzmann, H.** (2019). Asymptotic confidence sets for the jump curve in bivariate regression problems. *Journal of Multivariate Analysis*, 173, 291–312.
* **Bengs, V.**, and **Holzmann, H.** (2019). Adaptive confidence sets for kink estimation. *Electronic Journal of Statistics*, 1, 1523–1579.
* **Bengs, V., Busa-Fekete, R., El Mesaoudi-Paul, A.**, and **Hüllermeier, E.** (2021). Preference-based online learning with dueling bandits: A survey. *Journal of Machine Learning Research (JMLR)*, 22(7), 1–108.
* **Haddenhorst, B., Bengs, V.**, and **Hüllermeier, E.** (2021). On testing transitivity in online preference learning. *Machine Learning*, 110, 2063–2084.
* **Schede, E., Brandt, J., Tornede, A., Wever, M., Bengs, V., Hüllermeier, E.**, and **Tierney, K.** (2022). A survey of methods for automated algorithm configuration. *Journal of Artificial Intelligence Research*, 75, 425–487.
* **Bengs, V.**, and **Hüllermeier, E.** (2022). Multi-armed bandits with censored consumption of resources. *Machine Learning*, 112, 217–240.
* **Kolpaczki, P., Bengs, V.**, and **Hüllermeier, E.** (2024). Piecewise-stationary dueling bandits. *Transactions on Machine Learning Research*, 2835-8856.
* **Kaufmann, T., Weng, P., Bengs, V.**, and **Hüllermeier, E.** (2023). A survey of reinforcement learning from human feedback. [arXiv](https://arxiv.org/pdf/2312.14925). Accepted at *Transactions on Machine Learning Research*.

## International Conferences

* **Bengs, V.**, and **Hüllermeier, E.** (2020). Preselection bandits. *Proceedings of the 37th International Conference on Machine Learning (ICML)* in PMLR, 778–787.
* **El Mesaoudi-Paul, A., Weiß, D., Bengs, V., Hüllermeier, E.**, and **Tierney, K.** (2020). Pool-based realtime algorithm configuration: A preselection bandit approach. *International Conference on Learning and Intelligent Optimization (LION)*. Springer, Cham, 216–232.
* **Mohr, F., Bengs, V.**, and **Hüllermeier, E.** (2021). Single player Monte-Carlo tree search based on the Plackett-Luce model. *Proceedings of the AAAI Conference on Artificial Intelligence*, 35(14), 12373–12381.
* **Haddenhorst, B., Bengs, V., Brandt, J.**, and **Hüllermeier, E.** (2021). Testification of Condorcet winners in dueling bandits. *Conference on Uncertainty in Artificial Intelligence (UAI)*, 1195–1205.
* **Haddenhorst, B., Bengs, V.**, and **Hüllermeier, E.** (2021). Identification of the generalized Condorcet winner in multi-dueling bandits. *Advances in Neural Information Processing Systems (NeurIPS)*, 34, 25904–25916.
* **Tornede, A., Bengs, V.**, and **Hüllermeier, E.** (2022). Machine learning for online algorithm selection under censored feedback. *Proceedings of the AAAI Conference on Artificial Intelligence*, 36(9), 10370–10380.
* **Bengs, V., Saha, A.**, and **Hüllermeier, E.** (2022). Stochastic contextual dueling bandits under linear stochastic transitivity models. *Proceedings of the 39th International Conference on Machine Learning (ICML)* in PMLR, 1764–1786.
* **Bengs, V., Hüllermeier, E.**, and **Wageman, W.** (2022). Pitfalls of epistemic uncertainty quantification through loss minimisation. *NeurIPS*, 35, 29205–29216.
* **Brandt, J., Bengs, V., Haddenhorst, B.**, and **Hüllermeier, E.** (2022). Finding optimal arms in non-stochastic combinatorial bandits with semi-bandit feedback and finite budget. *NeurIPS*, 35, 20621–20634.
* **Brandt, J., Schede, E., Bengs, V., Haddenhorst, B., Hüllermeier, E.**, and **Tierney, K.** (2023). AC-Band: A combinatorial bandit-based approach to algorithm configuration. *Proceedings of the AAAI Conference on Artificial Intelligence*, 37(10), 12355–12363.
* **Mortier, T., Bengs, V., Hüllermeier, E., Stijn, L.**, and **Wageman, W.** (2023). Calibration of probabilistic classifier sets. *Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)* in PMLR, 8857–8870.
* **Bengs, V., Hüllermeier, E.**, and **Wageman, W.** (2023). On second-order scoring rules for epistemic uncertainty quantification. *ICML*, PMLR, 2078–2091.
* **Kolpaczki, P., Bengs, V., Muschalik, M.**, and **Hüllermeier, E.** (2024). Approximating the Shapley value without marginal contributions. *AAAI*, 38(12), 13246–13255.
* **Bengs, V., Haddenhorst, B.**, and **Hüllermeier, E.** (2024). Identifying Copeland winners in dueling bandits with indifferences. *AISTATS* in PMLR, 226–234.
* **Brandt, J., Wever, M., Bengs, V.**, and **Hüllermeier, E.** (2024). Best arm identification with retroactively increased sampling budget for more resource-efficient HPO. *IJCAI*, 3742–3750.
* **Sale, Y., Bengs, V., Caprio, M.**, and **Hüllermeier, E.** (2024). Second-order uncertainty quantification: A distance-based approach. *ICML*, PMLR, 43060–43076.
* **Jürgens, M., Bengs, V., Meinert, N., Hüllermeier, E.**, and **Waegeman, W.** (2024). Is epistemic uncertainty faithfully represented by second-order empirical risk minimization? *ICML*, PMLR, 22624–22642.
* **Thies, S. M., Alfaro, J. C.,**, and **Bengs, V.** (2024). MORE–PLR: Multi-output regression employed for partial label ranking. *Discovery Science*, 401–416.

## Workshop Publications

* **Kolpaczki, P., Bengs, V.**, and **Hüllermeier, E.** (2021). Identifying the top-k players in cooperative games via Shapley bandits. *LWDA 2021.*
* **Kaufmann, T., Bengs, V.**, and **Hüllermeier, E.** (2023). Reinforcement learning from human feedback for cyber-physical systems: On the potential of self-supervised pretraining. [ML4PCS](https://timokaufmann.com/assets/pdf/ml4cps_2023_final_submission_rlhf4cps.pdf).
* **Becker, P.**, and **Bengs, V.** (2023). Shapley-based feature selection for online algorithm selection. *DynXAI Workshop at ECML-PKDD 2023.*
* **Brandt, J., Schede, E., Shivam, S., Bengs, V., Hüllermeier, E.**, and **Tierney, K.** (2023). Contextual preselection methods in pool-based realtime algorithm configuration. *LWDA 2023.*
* **Yamagata, T., Oberkofler, T., Kaufmann, T., Bengs, V., Hüllermeier, E.**, and **Santos-Rodriguez, R.** (2024). Relatively rational: Learning utilities and rationalities jointly from pairwise preferences. *ICML 2024 Workshop on Models of Human Feedback for AI Alignment.*

## Working Papers

* **Thurner, P.W., Haggerty, F., Bengs, V.**, and **Hüllermeier, E.** (2023). Party Preference Orders at the German 2021 Federal Election.
* **Jürgens, M., Mortier, T., Hüllermeier, E., Bengs, V.,**, and **Waegeman, W.** (2025). A calibration test for evaluating set-based epistemic uncertainty representations. [arXiv](https://arxiv.org/abs/2502.16299).
* **Wang, J., Alfaro, J. C.,**, and **Bengs, V.** (2025). A comparative analysis of rank aggregation methods for the partial label ranking problem. [arXiv](https://arxiv.org/abs/2502.17077).


## Technical Reports

* **Bengs, V.**, and **Holzmann, H.** (2019). Uniform approximation in classical weak convergence theory. [arXiv:1903.09864](https://arxiv.org/abs/1903.09864).
